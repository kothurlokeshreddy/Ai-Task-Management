{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d418d8",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d3b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c15e8d",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5ec1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./enhanced_synthetic_task_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7472eefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_description</th>\n",
       "      <th>priority</th>\n",
       "      <th>deadline</th>\n",
       "      <th>assigned_to</th>\n",
       "      <th>status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>estimated_hours</th>\n",
       "      <th>actual_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TASK_00001</td>\n",
       "      <td>tv long impact need among difference get exper...</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Do</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>9.179174</td>\n",
       "      <td>9.174231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TASK_00002</td>\n",
       "      <td>everything security institution community stud...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>user_15</td>\n",
       "      <td>To Do</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>14.947183</td>\n",
       "      <td>16.873465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TASK_00003</td>\n",
       "      <td>size through do drop everybody. please do it asap</td>\n",
       "      <td>High</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>user_56</td>\n",
       "      <td>To Do</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>10.874983</td>\n",
       "      <td>10.951447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TASK_00004</td>\n",
       "      <td>century evening medical wife wonder hit baby. ...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>user_44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>7.166649</td>\n",
       "      <td>7.679903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TASK_00005</td>\n",
       "      <td>church appear score management baby.</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2025-05-13</td>\n",
       "      <td>user_3</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>5.725363</td>\n",
       "      <td>10.407275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      task_id                                   task_description priority  \\\n",
       "0  TASK_00001  tv long impact need among difference get exper...      Low   \n",
       "1  TASK_00002  everything security institution community stud...   Medium   \n",
       "2  TASK_00003  size through do drop everybody. please do it asap     High   \n",
       "3  TASK_00004  century evening medical wife wonder hit baby. ...   Medium   \n",
       "4  TASK_00005               church appear score management baby.   Medium   \n",
       "\n",
       "     deadline assigned_to       status  created_at  estimated_hours  \\\n",
       "0  2025-07-04         NaN        To Do  2025-05-28         9.179174   \n",
       "1  2025-05-15     user_15        To Do  2025-05-04        14.947183   \n",
       "2  2025-06-05     user_56        To Do  2025-04-07        10.874983   \n",
       "3  2025-06-24     user_44          NaN  2025-05-02         7.166649   \n",
       "4  2025-05-13      user_3  In Progress  2025-04-15         5.725363   \n",
       "\n",
       "   actual_hours  \n",
       "0      9.174231  \n",
       "1     16.873465  \n",
       "2     10.951447  \n",
       "3      7.679903  \n",
       "4     10.407275  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed8b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c36ab7",
   "metadata": {},
   "source": [
    "## check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8547f93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id               0\n",
       "task_description    500\n",
       "priority            500\n",
       "deadline              0\n",
       "assigned_to         500\n",
       "status              500\n",
       "created_at            0\n",
       "estimated_hours       0\n",
       "actual_hours          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061d9517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id             0\n",
       "task_description    0\n",
       "priority            0\n",
       "deadline            0\n",
       "assigned_to         0\n",
       "status              0\n",
       "created_at          0\n",
       "estimated_hours     0\n",
       "actual_hours        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df['task_description'].fillna(\"No description provided\", inplace=True)\n",
    "df['priority'].fillna(df['priority'].mode()[0], inplace=True)\n",
    "df['assigned_to'].fillna(\"unassigned\", inplace=True)\n",
    "df['status'].fillna(df['status'].mode()[0], inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef450146",
   "metadata": {},
   "source": [
    "## Target Variable : Priority\n",
    "\n",
    "#### We'll classify tasks based on a target variable. Assuming priority is the target (Low, Medium, High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4006b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['priority_encoded'] = label_encoder.fit_transform(df['priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d45f63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_description</th>\n",
       "      <th>priority</th>\n",
       "      <th>deadline</th>\n",
       "      <th>assigned_to</th>\n",
       "      <th>status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>estimated_hours</th>\n",
       "      <th>actual_hours</th>\n",
       "      <th>priority_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TASK_00001</td>\n",
       "      <td>tv long impact need among difference get exper...</td>\n",
       "      <td>Low</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>unassigned</td>\n",
       "      <td>To Do</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>9.179174</td>\n",
       "      <td>9.174231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TASK_00002</td>\n",
       "      <td>everything security institution community stud...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>user_15</td>\n",
       "      <td>To Do</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>14.947183</td>\n",
       "      <td>16.873465</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TASK_00003</td>\n",
       "      <td>size through do drop everybody. please do it asap</td>\n",
       "      <td>High</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>user_56</td>\n",
       "      <td>To Do</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>10.874983</td>\n",
       "      <td>10.951447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TASK_00004</td>\n",
       "      <td>century evening medical wife wonder hit baby. ...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>user_44</td>\n",
       "      <td>To Do</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>7.166649</td>\n",
       "      <td>7.679903</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TASK_00005</td>\n",
       "      <td>church appear score management baby.</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2025-05-13</td>\n",
       "      <td>user_3</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>5.725363</td>\n",
       "      <td>10.407275</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      task_id                                   task_description priority  \\\n",
       "0  TASK_00001  tv long impact need among difference get exper...      Low   \n",
       "1  TASK_00002  everything security institution community stud...   Medium   \n",
       "2  TASK_00003  size through do drop everybody. please do it asap     High   \n",
       "3  TASK_00004  century evening medical wife wonder hit baby. ...   Medium   \n",
       "4  TASK_00005               church appear score management baby.   Medium   \n",
       "\n",
       "     deadline assigned_to       status  created_at  estimated_hours  \\\n",
       "0  2025-07-04  unassigned        To Do  2025-05-28         9.179174   \n",
       "1  2025-05-15     user_15        To Do  2025-05-04        14.947183   \n",
       "2  2025-06-05     user_56        To Do  2025-04-07        10.874983   \n",
       "3  2025-06-24     user_44        To Do  2025-05-02         7.166649   \n",
       "4  2025-05-13      user_3  In Progress  2025-04-15         5.725363   \n",
       "\n",
       "   actual_hours  priority_encoded  \n",
       "0      9.174231                 2  \n",
       "1     16.873465                 3  \n",
       "2     10.951447                 1  \n",
       "3      7.679903                 3  \n",
       "4     10.407275                 3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2538da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Critical' 'High' 'Low' 'Medium']\n"
     ]
    }
   ],
   "source": [
    "# View encoded classes\n",
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b2ccc",
   "metadata": {},
   "source": [
    "## Feature Extraction using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "208f50a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert text column to TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=3000)\n",
    "X_tfidf = tfidf.fit_transform(df['task_description'])\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = X_tfidf\n",
    "y = df['priority_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc07c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x975 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 99472 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48efb220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       3\n",
       "2       1\n",
       "3       3\n",
       "4       3\n",
       "       ..\n",
       "9995    3\n",
       "9996    3\n",
       "9997    3\n",
       "9998    3\n",
       "9999    3\n",
       "Name: priority_encoded, Length: 10000, dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283110c",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3c4b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f1515e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x975 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 79728 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98726ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x975 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19744 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bdb6d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9254    3\n",
       "1561    3\n",
       "1670    3\n",
       "6087    0\n",
       "6669    2\n",
       "       ..\n",
       "5734    3\n",
       "5191    3\n",
       "5390    3\n",
       "860     0\n",
       "7270    1\n",
       "Name: priority_encoded, Length: 8000, dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8eb6967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6252    1\n",
       "4684    2\n",
       "1731    3\n",
       "4742    3\n",
       "4521    0\n",
       "       ..\n",
       "6412    3\n",
       "8285    3\n",
       "7853    3\n",
       "1095    1\n",
       "6929    1\n",
       "Name: priority_encoded, Length: 2000, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b960448",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6de0dbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "\n",
      "[[  0  14   0 178]\n",
      " [  0  37   0 527]\n",
      " [  0  26   0 348]\n",
      " [  0  45   2 823]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.00      0.00      0.00       192\n",
      "        High       0.30      0.07      0.11       564\n",
      "         Low       0.00      0.00      0.00       374\n",
      "      Medium       0.44      0.95      0.60       870\n",
      "\n",
      "    accuracy                           0.43      2000\n",
      "   macro avg       0.19      0.25      0.18      2000\n",
      "weighted avg       0.28      0.43      0.29      2000\n",
      "\n",
      "Accuracy: 43.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reddy\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\reddy\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\reddy\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "priority_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Naive Bayes Results:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb, target_names=label_encoder.classes_))\n",
    "print(f\"Accuracy: {priority_accuracy * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa705ca",
   "metadata": {},
   "source": [
    "## SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fccf2a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "\n",
      "[[  1  58  16 117]\n",
      " [  5 144  62 353]\n",
      " [  6 101  35 232]\n",
      " [ 16 205  76 573]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.04      0.01      0.01       192\n",
      "        High       0.28      0.26      0.27       564\n",
      "         Low       0.19      0.09      0.12       374\n",
      "      Medium       0.45      0.66      0.53       870\n",
      "\n",
      "    accuracy                           0.38      2000\n",
      "   macro avg       0.24      0.25      0.23      2000\n",
      "weighted avg       0.31      0.38      0.33      2000\n",
      "\n",
      "Accuracy : 37.65%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train model\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "priority_svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Evaluate\n",
    "print(\"SVM Results:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_))\n",
    "print(f\"Accuracy : {priority_svm_accuracy * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f986dd3d",
   "metadata": {},
   "source": [
    "## Target Variable : Status\n",
    "\n",
    "#### We'll classify tasks based on a target variable. Assuming status is the target (To Do, In Progress, Done, Blocked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cae2771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blocked', 'Done', 'In Progress', 'To Do'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_label_encoder = LabelEncoder()\n",
    "df['status_encoded'] = status_label_encoder.fit_transform(df['status'])\n",
    "\n",
    "#view encoded class labels\n",
    "status_label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21a59433",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df['status_encoded']\n",
    "\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d9fb7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9069    1\n",
       "2603    2\n",
       "7738    3\n",
       "1579    1\n",
       "5058    3\n",
       "       ..\n",
       "5734    0\n",
       "5191    2\n",
       "5390    0\n",
       "860     2\n",
       "7270    2\n",
       "Name: status_encoded, Length: 7000, dtype: int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "184e0c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6252    3\n",
       "4684    3\n",
       "1731    0\n",
       "4742    2\n",
       "4521    1\n",
       "       ..\n",
       "8014    2\n",
       "1074    1\n",
       "3063    0\n",
       "6487    3\n",
       "4705    3\n",
       "Name: status_encoded, Length: 3000, dtype: int32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc420129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "\n",
      "[[   0    0   12  276]\n",
      " [   0    1   24  506]\n",
      " [   0    3   40  833]\n",
      " [   0    1   54 1250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.00      0.00      0.00       288\n",
      "        High       0.20      0.00      0.00       531\n",
      "         Low       0.31      0.05      0.08       876\n",
      "      Medium       0.44      0.96      0.60      1305\n",
      "\n",
      "    accuracy                           0.43      3000\n",
      "   macro avg       0.24      0.25      0.17      3000\n",
      "weighted avg       0.32      0.43      0.28      3000\n",
      "\n",
      "Accuracy : 43.03%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reddy\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\reddy\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\reddy\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, z_train)\n",
    "\n",
    "# Predict\n",
    "z_pred_nb = nb_model.predict(X_test)\n",
    "status_accuracy = accuracy_score(z_test, z_pred_nb)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Naive Bayes Results:\\n\")\n",
    "print(confusion_matrix(z_test, z_pred_nb))\n",
    "print(classification_report(z_test, z_pred_nb, target_names=label_encoder.classes_))\n",
    "print(f\"Accuracy : {status_accuracy * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d87c8455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "\n",
      "[[  5  33  66 184]\n",
      " [ 11  73 119 328]\n",
      " [ 17 106 195 558]\n",
      " [ 35 152 293 825]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.07      0.02      0.03       288\n",
      "        High       0.20      0.14      0.16       531\n",
      "         Low       0.29      0.22      0.25       876\n",
      "      Medium       0.44      0.63      0.52      1305\n",
      "\n",
      "    accuracy                           0.37      3000\n",
      "   macro avg       0.25      0.25      0.24      3000\n",
      "weighted avg       0.32      0.37      0.33      3000\n",
      "\n",
      "Accuracy : 36.60%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classficiation\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train model\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, z_train)\n",
    "\n",
    "# Predict\n",
    "z_pred_svm = svm_model.predict(X_test)\n",
    "status_svm_accuracy = accuracy_score(z_test, z_pred_svm)\n",
    "\n",
    "# Evaluate\n",
    "print(\"SVM Results:\\n\")\n",
    "print(confusion_matrix(z_test, z_pred_svm))\n",
    "print(classification_report(z_test, z_pred_svm, target_names=label_encoder.classes_))\n",
    "print(f\"Accuracy : {status_svm_accuracy * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca67d5d",
   "metadata": {},
   "source": [
    "## Overall Results till now\n",
    "\n",
    "| Metrics  | Naive Bayes | SVM    | Target Variable |\n",
    "| -------- | ----------- | ------ | --------------- |\n",
    "| Accuracy | 42%         | 37.65% | Priority        |\n",
    "| Accuracy | 43%         | 37.45% | Status          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38109a16",
   "metadata": {},
   "source": [
    "## Check for Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32831938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium      4233\n",
      "High        2904\n",
      "Low         1915\n",
      "Critical     948\n",
      "Name: priority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['priority'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65961080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Do          4341\n",
      "In Progress    2841\n",
      "Done           1884\n",
      "Blocked         934\n",
      "Name: status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486fd08e",
   "metadata": {},
   "source": [
    "### By the above results, we can get to know the classes are imbalanced. So, for that we try to balance the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47655e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Example: Upsample minority classes\n",
    "df_majority = df[df['priority'] == 'Low']\n",
    "df_minority = df[df['priority'] != 'Low']\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f709186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low         1915\n",
      "Medium      1010\n",
      "High         671\n",
      "Critical     234\n",
      "Name: priority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_balanced['priority'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4223d8f",
   "metadata": {},
   "source": [
    "### Still, the classes are imbalanced, let's try to add more features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d94724ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "\n",
      "[[   0   56    4  227]\n",
      " [   0  157   13  667]\n",
      " [   0  106   10  452]\n",
      " [   0  211   15 1082]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.00      0.00      0.00       287\n",
      "        High       0.30      0.19      0.23       837\n",
      "         Low       0.24      0.02      0.03       568\n",
      "      Medium       0.45      0.83      0.58      1308\n",
      "\n",
      "    accuracy                           0.42      3000\n",
      "   macro avg       0.24      0.26      0.21      3000\n",
      "weighted avg       0.32      0.42      0.32      3000\n",
      "\n",
      "Accuracy: 41.63%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reddy\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\reddy\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\reddy\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Convert categorical features\n",
    "encoder = OneHotEncoder()\n",
    "categorical_features = encoder.fit_transform(df[['assigned_to', 'status']])\n",
    "\n",
    "# Combine with TF-IDF matrix\n",
    "A = hstack([X_tfidf, categorical_features])\n",
    "\n",
    "\n",
    "# Train Test Split\n",
    "A_train, A_test, y_train, y_test = train_test_split(A, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(A_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_nb = nb_model.predict(A_test)\n",
    "priority_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Naive Bayes Results:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb, target_names=label_encoder.classes_))\n",
    "print(f\"Accuracy: {priority_accuracy * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6d4c2",
   "metadata": {},
   "source": [
    "### Try with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84c776aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be42b995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SVM model trained with best hyperparameters.\n",
      "\n",
      "Final SVM Model Performance on Test Set:\n",
      "Accuracy : 43.60%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Best params from your tuning\n",
    "best_c = 0.1\n",
    "best_kernel = 'linear'\n",
    "\n",
    "# Initialize the final model with the best parameters\n",
    "final_svm_model = SVC(C=best_c, kernel=best_kernel, random_state=42) # Add random_state for reproducibility\n",
    "\n",
    "# Train the final model on the entire training data\n",
    "# Make sure X_train and y_train are your full training sets (not just a fold)\n",
    "final_svm_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Final SVM model trained with best hyperparameters.\")\n",
    "\n",
    "# Make predictions on the unseen test data\n",
    "y_pred_final_svm = final_svm_model.predict(X_test)\n",
    "Updated_accuracy = accuracy_score(y_test, y_pred_final_svm)\n",
    "\n",
    "# Evaluate the final model\n",
    "print(\"\\nFinal SVM Model Performance on Test Set:\")\n",
    "print(f\"Accuracy : {Updated_accuracy * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78c081",
   "metadata": {},
   "source": [
    "## Advanced Resampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7d5b0",
   "metadata": {},
   "source": [
    "### Step 1: Preparing Data (Pre-Resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2c05e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in d:\\anaconda\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\reddy\\appdata\\roaming\\python\\python311\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Original X_train shape: (8000, 975)\n",
      "Original y_train shape: (8000,)\n",
      "Original y_test shape: (2000,)\n",
      "\n",
      "Class distribution in original y_train:\n",
      "Counter({3: 3387, 1: 2323, 2: 1532, 0: 758})\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y) # stratify=y is crucial for imbalanced data)\n",
    "                                                    \n",
    "print(f\"Original X_train shape: {X_train.shape}\")\n",
    "print(f\"Original y_train shape: {y_train.shape}\")\n",
    "print(f\"Original y_test shape: {y_test.shape}\")\n",
    "                                                    \n",
    "# Check initial class distribution in y_train (optional, but good practice)\n",
    "from collections import Counter\n",
    "print(\"\\nClass distribution in original y_train:\")\n",
    "print(Counter(y_train))                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65af9a",
   "metadata": {},
   "source": [
    "### Step - 2 : Apply SMOTE to the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c586522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resampled X_train shape: (13548, 975)\n",
      "Resampled y_train shape: (13548,)\n",
      "\n",
      "Class distribution in resampled y_train:\n",
      "Counter({3: 3387, 0: 3387, 1: 3387, 2: 3387})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np # For potential use with sparse matrices if needed\n",
    "\n",
    "smote = SMOTE(random_state=RANDOM_SEED)\n",
    "\n",
    "# Apply SMOTE to your training data ONLY\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"\\nResampled X_train shape: {X_train_resampled.shape}\")\n",
    "print(f\"Resampled y_train shape: {y_train_resampled.shape}\")\n",
    "\n",
    "print(\"\\nClass distribution in resampled y_train:\")\n",
    "print(Counter(y_train_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3015158e",
   "metadata": {},
   "source": [
    "### Step - 3 : Train the model on resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11931965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SVM model trained with SMOTE-resampled data.\n",
      "\n",
      "Final SVM Model Performance on Original Test Set (after SMOTE):\n",
      "Accuracy : 27.10%\n",
      "\n",
      "[[ 31  51  56  52]\n",
      " [ 96 134 167 184]\n",
      " [ 68  96 107 112]\n",
      " [169 178 229 270]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.09      0.16      0.11       190\n",
      "        High       0.29      0.23      0.26       581\n",
      "         Low       0.19      0.28      0.23       383\n",
      "      Medium       0.44      0.32      0.37       846\n",
      "\n",
      "    accuracy                           0.27      2000\n",
      "   macro avg       0.25      0.25      0.24      2000\n",
      "weighted avg       0.31      0.27      0.29      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC # Or LinearSVC, depending on what you decided for best params\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder # Assuming you still need this for target_names\n",
    "\n",
    "final_svm_model_smote = SVC(C=0.1, kernel='linear', random_state=RANDOM_SEED) # Assuming these are your best params\n",
    "\n",
    "# Train the model on the RESAMPLED training data\n",
    "final_svm_model_smote.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Final SVM model trained with SMOTE-resampled data.\")\n",
    "\n",
    "# Make predictions on the unseen test data\n",
    "y_pred_smote_svm = final_svm_model_smote.predict(X_test)\n",
    "resampled_accuracy = accuracy_score(y_test, y_pred_smote_svm)\n",
    "\n",
    "# Evaluate the final model\n",
    "print(\"\\nFinal SVM Model Performance on Original Test Set (after SMOTE):\")\n",
    "print(f\"Accuracy : {resampled_accuracy * 100:.2f}%\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_smote_svm))\n",
    "print(classification_report(y_test, y_pred_smote_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7e9f2",
   "metadata": {},
   "source": [
    "## Accuracy Dropped, So let's try with another technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1fe7ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.12      0.01      0.01       190\n",
      "        High       0.29      0.14      0.19       581\n",
      "         Low       0.20      0.10      0.14       383\n",
      "      Medium       0.43      0.77      0.55       846\n",
      "\n",
      "    accuracy                           0.39      2000\n",
      "   macro avg       0.26      0.25      0.22      2000\n",
      "weighted avg       0.32      0.39      0.32      2000\n",
      "\n",
      "Accuracy : 38.60%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Class Weights (instead of SMOTE)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=0.1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Switch to Tree-based Models (Handle imbalance better)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate Using Per-Class F1-Scores, Not Just Accuracy\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))\n",
    "print(f\"Accuracy : {rf_accuracy * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008b38c",
   "metadata": {},
   "source": [
    "## Trial with Random Sampler Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da20f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random OverSampler Results ===\n",
      "Accuracy: 0.3720106288751107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.41      0.53      0.46       847\n",
      "        High       0.36      0.30      0.33       846\n",
      "         Low       0.37      0.37      0.37       847\n",
      "      Medium       0.33      0.29      0.31       847\n",
      "\n",
      "    accuracy                           0.37      3387\n",
      "   macro avg       0.37      0.37      0.37      3387\n",
      "weighted avg       0.37      0.37      0.37      3387\n",
      "\n",
      "[[451 120 138 138]\n",
      " [217 253 194 182]\n",
      " [197 163 313 174]\n",
      " [240 173 191 243]]\n",
      "\n",
      "=== Random UnderSampler Results ===\n",
      "Accuracy: 0.27140974967061926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.25      0.27      0.26       190\n",
      "        High       0.27      0.30      0.28       189\n",
      "         Low       0.30      0.26      0.28       190\n",
      "      Medium       0.28      0.25      0.26       190\n",
      "\n",
      "    accuracy                           0.27       759\n",
      "   macro avg       0.27      0.27      0.27       759\n",
      "weighted avg       0.27      0.27      0.27       759\n",
      "\n",
      "[[52 52 38 48]\n",
      " [56 57 35 41]\n",
      " [57 47 49 37]\n",
      " [43 55 44 48]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# ========== RANDOM OVERSAMPLING ==========\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "X_train_ros, X_test_ros, y_train_ros, y_test_ros = train_test_split(X_ros, y_ros, test_size=0.2, random_state=42, stratify=y_ros)\n",
    "\n",
    "model_ros = MultinomialNB()\n",
    "model_ros.fit(X_train_ros, y_train_ros)\n",
    "y_pred_ros = model_ros.predict(X_test_ros)\n",
    "\n",
    "print(\"=== Random OverSampler Results ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_ros, y_pred_ros))\n",
    "print(classification_report(y_test_ros, y_pred_ros, target_names=label_encoder.classes_))\n",
    "print(confusion_matrix(y_test_ros, y_pred_ros))\n",
    "\n",
    "\n",
    "# ========== RANDOM UNDERSAMPLING ==========\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "\n",
    "X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus, y_rus, test_size=0.2, random_state=42, stratify=y_rus)\n",
    "\n",
    "model_rus = MultinomialNB()\n",
    "model_rus.fit(X_train_rus, y_train_rus)\n",
    "y_pred_rus = model_rus.predict(X_test_rus)\n",
    "\n",
    "print(\"\\n=== Random UnderSampler Results ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_rus, y_pred_rus))\n",
    "print(classification_report(y_test_rus, y_pred_rus, target_names=label_encoder.classes_))\n",
    "print(confusion_matrix(y_test_rus, y_pred_rus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dbc5bf",
   "metadata": {},
   "source": [
    "## Let's switch to class weighted svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91dfb147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.10      0.16      0.12       190\n",
      "        High       0.30      0.25      0.27       581\n",
      "         Low       0.22      0.21      0.22       383\n",
      "      Medium       0.42      0.42      0.42       846\n",
      "\n",
      "    accuracy                           0.31      2000\n",
      "   macro avg       0.26      0.26      0.26      2000\n",
      "weighted avg       0.32      0.31      0.31      2000\n",
      "\n",
      "[[ 30  46  35  79]\n",
      " [ 80 145  95 261]\n",
      " [ 50  98  82 153]\n",
      " [139 188 165 354]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "weight_dict = dict(zip(np.unique(y), class_weights))\n",
    "\n",
    "# Train/test split on original cleaned data (no oversampling)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = LinearSVC(class_weight=weight_dict, max_iter=10000)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5e1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
